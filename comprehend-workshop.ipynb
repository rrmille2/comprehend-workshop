{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Textract and Amazon Comprehend AI Services\n",
    "### Example on extracting insights from a PDF Document\n",
    "\n",
    "\n",
    "## Contents \n",
    "1. [Background](#Background)\n",
    "1. [Notes and Configuration](#Notes-and-Configuration)\n",
    "1. [Amazon Textract](#Amazon-Textract)\n",
    "1. [Amazon Comprehend](#Amazon-Comprehend)\n",
    "1. [Key Phrase Extraction](#Key-Phrase-Extraction)\n",
    "1. [Sentiment Analysis](#Sentiment-Analysis)\n",
    "1. [Entity Recognition](#Entity-Recognition)\n",
    "1. [PII Entity Recognition](#PII-Entity-Recognition)\n",
    "1. [Topic Modeling](#Topic-Modeling)\n",
    "\n",
    "\n",
    "  \n",
    "## Background\n",
    "The goal of this exercise is to learn some insights from an existing PDF document. This is done by using Amazon Textract to extract the text from the document. This text is then analyzed by several Amazon Comprehend services to produce some insights about the document.  \n",
    "\n",
    "The PDF document used in this example is a ...\n",
    "\n",
    "## Notes and Configuration\n",
    "* Kernel `Python 3 (Data Science)` works well with this notebook\n",
    "* The CSV results files produced by this script use the pipe '|' symbol as a delimiter. When viewing these files in SageMaker Studio, be sure and change the Delimiter to 'pipe'.\n",
    "\n",
    "\n",
    "#### Regarding IAM Roles and Permissions:\n",
    "\n",
    "Within SageMaker Studio, each SageMaker User has an IAM Role known as the `SageMaker Execution Role`. Each Notebook for this user will run with this Role and the Permissions specified by this Role. The name of this Role can be found in the Details section of each SageMaker User in the AWS Console.\n",
    "\n",
    "For the code which runs in this notebook, the `SageMaker Execution Role` needs additional permissions to allow it to use Amazon Textract and Amazon Comprehend. In the AWS Console, navigate to the IAM service and add these two services to your SageMaker Execution Role:\n",
    "- AmazonTextractFullAccess\n",
    "- AmazonComprehendFullAccess\n",
    "\n",
    "Also, an Amazon Comprehend service Role needs to be created to grant Amazon Comprehend read access to your input data.  \n",
    "When creating this new Role, the default Policies are sufficient (i.e., no other Policies need to be added/modified).\n",
    "\n",
    "Lastly, the `SageMaker Execution Role` must be allowed to Pass the Comprehend Service Role. To allow this, you must attach a Policy to the `SageMaker Execution Role`. Below, the Resource entry is the ARN of the Comprehend service Role which you created. You can either create this as a new Policy and attach it or add it as an in-line Policy.\n",
    "\n",
    "    {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"iam:GetRole\",\n",
    "                    \"iam:PassRole\"\n",
    "                ],\n",
    "                \"Resource\": \"arn:aws:iam::810190279255:role/amComprehendServiceRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import boto3\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Set some variables that will be used throughout this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-east-1'\n",
    "\n",
    "# change this to an existing S3 bucket in your AWS account\n",
    "s3bucket = 'am-tmp2'\n",
    "s3prefix = 'comprehend'\n",
    "\n",
    "# this is where the various analysis results files will be stored on the local file system of this SageMaker instance\n",
    "results_dir = './results'\n",
    "!mkdir -p $results_dir\n",
    "\n",
    "# this is the IAM Role that defines which permissions this SageMaker instance has\n",
    "sm_execution_role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Functions\n",
    "The following functions provide a wrapper around the actual API calls for Amazon Textract and Amazon Comprehend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Textract\n",
    "Amazon Textract is a machine learning service that automatically extracts text, handwriting and data from scanned documents that goes beyond simple optical character recognition (OCR) to identify, understand, and extract data from forms and tables.  \n",
    "  \n",
    "In the next few cells the following steps will be performed:\n",
    "1. A specified PDF document will be uploaded to Amazon S3 to be analyzed by Amazon Textract.  \n",
    "1. The result of this analysis is a JSON file with each element containing details about a specific instance of text in the PDF.  \n",
    "1. This JSON file is copied from S3 to this local SageMaker instance.  \n",
    "1. The JSON file is then read and post-processed to produce a text file with one tweet (or other social media post) per line.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boto3 session\n",
    "# this session will be used for the remainder of this notebook\n",
    "session = boto3.Session(region_name=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/amazon-press-release.png to s3://am-tmp2/comprehend/amazon-press-release.png\n",
      "JobId: 6abdedb8e09bd13c876c29b4ff0716d912856a4bf455f9cae5e1703418bf13a9\n"
     ]
    }
   ],
   "source": [
    "# create the Textract Job\n",
    "textract_src_filename = 'amazon-press-release.png'\n",
    "\n",
    "# upload the PDF to S3 for Textract to process\n",
    "!aws s3 cp data/$textract_src_filename s3://$s3bucket/$s3prefix/$textract_src_filename\n",
    "\n",
    "\n",
    "textract_client = session.client('textract')\n",
    "response = textract_client.start_document_text_detection(\n",
    "    DocumentLocation={\n",
    "    'S3Object': {\n",
    "        'Bucket': s3bucket,\n",
    "        'Name': f'{s3prefix}/{textract_src_filename}'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "JobId = response[\"JobId\"]\n",
    "print('JobId: %s' % (JobId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "response = textract_client.get_document_text_detection(JobId=JobId)\n",
    "print(response['JobStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response['JobStatus'] != 'SUCCEEDED':\n",
    "    raise\n",
    "    \n",
    "pages = []\n",
    "while(True):\n",
    "    pages.append(response)\n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']\n",
    "        response = client.get_document_text_detection(JobId=JobId, NextToken=nextToken)\n",
    "\n",
    "    if nextToken == None:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "# iterate through the Textract JSON response, looking for the LINE and WORD entries\n",
    "for page in pages:\n",
    "    for blk in page['Blocks']:\n",
    "        if blk['BlockType'] in ['LINE']:\n",
    "            lines.append(blk['Text'])\n",
    "\n",
    "textract_results_filename = 'textract-results.txt'\n",
    "with open(f'./results/{textract_results_filename}', 'w') as fd:\n",
    "    for line in lines:\n",
    "        fd.write(f'{line}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['August 24, 2017 at 1:45 PM EDT',\n",
       " 'SEATTLE & AUSTIN, WIRE)--Aug. 24, 2017- NASDAQ:AMZN)-Amazon and Whole Foods',\n",
       " \"Market today announced that Amazon's acquisition of Whole Foods Market will close on Monday August 28,\",\n",
       " \"2017, and the two companies will together pursue the vision of making Whole Foods Market's high-quality,\",\n",
       " 'natural and organic food affordable for everyone. As a down payment on that vision, Whole Foods Market will',\n",
       " 'offer lower prices starting Monday on a selection of best-selling grocery staples across its stores, with more to',\n",
       " 'come.',\n",
       " 'In addition, Amazon and Whole Foods Market technology teams will begin to integrate Amazon Prime into',\n",
       " 'the Whole Foods Market point-of-sale system, and when this work is complete, Prime members will receive',\n",
       " 'special savings and in-store benefits. The two companies will invent in additional areas over time, including in',\n",
       " 'merchandising and logistics, to enable lower prices for Whole Foods Market customers.',\n",
       " '\"We\\'re determined to make healthy and organic food affordable for everyone. Everybody should be able to',\n",
       " \"eat Whole Foods Market quality - we will lower prices without compromising Whole Foods Market's long-held\",\n",
       " 'commitment to the highest standards,\" said Jeff Wilke, CEO of Amazon Worldwide Consumer. \"To get started,',\n",
       " \"we're going to lower prices beginning Monday on a selection of best-selling grocery staples, including Whole\",\n",
       " 'Trade organic bananas, responsibly-farmed salmon, organic large brown eggs, animal-welfare-rated 85% lean',\n",
       " 'ground beef, and more. And this is just the beginning - we will make Amazon Prime the customer rewards',\n",
       " 'program at Whole Foods Market and continuously lower prices as we invent together. There is significant work',\n",
       " 'and opportunity ahead, and we\\'re thrilled to get started.\"',\n",
       " '\"It\\'s been our mission for 39 years at Whole Foods Market to bring the highest quality food to our customers,\"',\n",
       " 'said John Mackey, Whole Foods Market co-founder and CEO. \"By working together with Amazon and',\n",
       " 'integrating in several key areas, we can lower prices and double down on that mission and reach more people',\n",
       " \"with Whole Foods Market's high-quality, natural and organic food. As part of our commitment to quality, we'll\",\n",
       " \"continue to expand our efforts to support and promote local products and suppliers. We can't wait to start\",\n",
       " 'showing customers what\\'s possible when Whole Foods Market and Amazon innovate together.\"',\n",
       " \"Here's what will be new in Whole Foods Market stores on Monday and what customers can expect over time\",\n",
       " 'as the two companies integrate:',\n",
       " 'Starting Monday, Whole Foods Market will offer lower prices on a selection of best-selling staples across',\n",
       " 'its stores, with much more to come. Customers will enjoy lower prices on products like Whole Trade',\n",
       " 'bananas, organic avocados, organic large brown eggs, organic responsibly-farmed salmon and tilapia,',\n",
       " 'organic baby kale and baby lettuce, animal-welfare-rated 85% lean ground beef, creamy and crunchy',\n",
       " 'almond butter, organic Gala and Fuji apples, organic rotisserie chicken, 365 Everyday Value organic butter,',\n",
       " 'and much more.',\n",
       " 'In the future, after certain technical integration work is complete, Amazon Prime will become Whole',\n",
       " \"Foods Market's customer rewards program, providing Prime members with special savings and other in-\",\n",
       " 'store benefits.',\n",
       " \"Whole Foods Market's healthy and high-quality private label products-including 365 Everyday Value,\",\n",
       " 'Whole Foods Market, Whole Paws and Whole Catch-will be available through Amazon.com,',\n",
       " 'AmazonFresh, Prime Pantry and Prime Now.',\n",
       " 'Amazon Lockers will be available in select Whole Foods Market stores. Customers can have products',\n",
       " 'shipped from Amazon.com to their local Whole Foods Market store for pick up or send returns back to',\n",
       " 'Amazon during a trip to the store.',\n",
       " 'This is just the beginning - Amazon and Whole Foods Market plan to offer more in-store benefits and lower',\n",
       " 'prices for customers over time as the two companies integrate logistics and point-of-sale and merchandising',\n",
       " 'systems.',\n",
       " 'Whole Foods Market will continue to grow its team and create jobs in local communities as it opens new',\n",
       " 'stores, hires new team members, and expands its support of local farmers and artisans. The company will',\n",
       " 'maintain operations under the Whole Foods Market brand, preserve its high standards and commitment to',\n",
       " 'providing the finest natural and organic foods, and continue to source from trusted vendors and partners',\n",
       " \"around the world. John Mackey will remain as CEO and Whole Foods Market's headquarters will stay in Austin,\",\n",
       " 'Texas.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Comprehend\n",
    "Amazon Comprehend is a natural language processing (NLP) service that uses machine learning to discover insights from text. The service provides APIs for Keyphrase Extraction, Sentiment Analysis, Entity Recognition, Topic Modeling, and Language Detection so you can easily integrate natural language processing into your applications. The following cells will walk through several examples of how to use the API.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrase Extraction\n",
    "Use Amazon Comprehend to extract Key Phrases in the text from the Textract analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the comprehend boto3 client (from the existing boto3 session)\n",
    "comp_client = session.client('comprehend')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phrases = []\n",
    "\n",
    "for line in lines:     \n",
    "    response = comp_client.detect_key_phrases(Text=line, LanguageCode='en')\n",
    "    for kp in response['KeyPhrases']:\n",
    "        if kp['Text'] not in key_phrases:\n",
    "            key_phrases.append(kp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sentiment Analysis\n",
    "Use Amazon Comprehend to determine the Sentiment of each line of text from the Textract analysis.\n",
    "* POSITIVE, NEUTRAL, NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Started Comprehend Sentiment Analysis job')\n",
    "# sentiments = GetSentiments(comp_client, textract_results_filename, comprehend_sentiments_results_filename)\n",
    "# print('See results file: %s\\n' % (comprehend_sentiments_results_filename))\n",
    "\n",
    "# freq = CalcFrequencies(sentiments)\n",
    "# print('Frequencies:')\n",
    "# for d in sentiments:\n",
    "#     print('%s: %.2f' % (d, freq[d]))        \n",
    "\n",
    "    \n",
    "# keep a running total of the various sentiments\n",
    "sentiments = []\n",
    "    \n",
    "\n",
    "for line in lines:\n",
    "    response = comp_client.detect_sentiment(Text=line, LanguageCode='en')\n",
    "    sentiments.append(response['Sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'POSITIVE',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL',\n",
       " 'POSITIVE',\n",
       " 'NEUTRAL',\n",
       " 'NEUTRAL']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Entity Recognition\n",
    "Use Amazon Comprehend to detect Entities in the text from the Textract analysis.  \n",
    "What are the type of Entities?\n",
    "* PERSON, ORGANIZATION, DATE, QUANTITY, LOCATION, TITLE, COMMERCIAL_ITEM, EVENT, OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entities = []\n",
    "for line in lines:\n",
    "    response = comp_client.detect_entities(Text=line, LanguageCode='en')\n",
    "    entities.append(response['Entities'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Score': 0.9941008687019348,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'August 24, 2017 at 1:45 PM EDT',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 30}],\n",
       " [{'Score': 0.9128297567367554,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'SEATTLE & AUSTIN, WIRE',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 22},\n",
       "  {'Score': 0.9979518055915833,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'Aug. 24, 2017',\n",
       "   'BeginOffset': 25,\n",
       "   'EndOffset': 38},\n",
       "  {'Score': 0.9296031594276428,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'NASDAQ',\n",
       "   'BeginOffset': 40,\n",
       "   'EndOffset': 46},\n",
       "  {'Score': 0.7923950552940369,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'AMZN',\n",
       "   'BeginOffset': 47,\n",
       "   'EndOffset': 51},\n",
       "  {'Score': 0.9962045550346375,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 53,\n",
       "   'EndOffset': 59},\n",
       "  {'Score': 0.8217054009437561,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods',\n",
       "   'BeginOffset': 64,\n",
       "   'EndOffset': 75}],\n",
       " [{'Score': 0.9663324356079102,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Market',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 6},\n",
       "  {'Score': 0.9905973076820374,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'today',\n",
       "   'BeginOffset': 7,\n",
       "   'EndOffset': 12},\n",
       "  {'Score': 0.9985026121139526,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 28,\n",
       "   'EndOffset': 34},\n",
       "  {'Score': 0.9792006015777588,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 52,\n",
       "   'EndOffset': 70},\n",
       "  {'Score': 0.9991075396537781,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'Monday August 28',\n",
       "   'BeginOffset': 85,\n",
       "   'EndOffset': 101}],\n",
       " [{'Score': 0.981730580329895,\n",
       "   'Type': 'DATE',\n",
       "   'Text': '2017',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 4},\n",
       "  {'Score': 0.9895932674407959,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': 'two companies',\n",
       "   'BeginOffset': 14,\n",
       "   'EndOffset': 27}],\n",
       " [{'Score': 0.514271080493927,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Foods Market',\n",
       "   'BeginOffset': 90,\n",
       "   'EndOffset': 102}],\n",
       " [{'Score': 0.9966026544570923,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'Monday',\n",
       "   'BeginOffset': 28,\n",
       "   'EndOffset': 34}],\n",
       " [],\n",
       " [{'Score': 0.9971610307693481,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 13,\n",
       "   'EndOffset': 19},\n",
       "  {'Score': 0.9912534356117249,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 84,\n",
       "   'EndOffset': 90},\n",
       "  {'Score': 0.9750593304634094,\n",
       "   'Type': 'COMMERCIAL_ITEM',\n",
       "   'Text': 'Prime',\n",
       "   'BeginOffset': 91,\n",
       "   'EndOffset': 96}],\n",
       " [{'Score': 0.46154284477233887,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Market',\n",
       "   'BeginOffset': 16,\n",
       "   'EndOffset': 22}],\n",
       " [{'Score': 0.866830587387085,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': 'two companies',\n",
       "   'BeginOffset': 43,\n",
       "   'EndOffset': 56}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.9998101592063904,\n",
       "   'Type': 'PERSON',\n",
       "   'Text': 'Jeff Wilke',\n",
       "   'BeginOffset': 43,\n",
       "   'EndOffset': 53},\n",
       "  {'Score': 0.7953994274139404,\n",
       "   'Type': 'PERSON',\n",
       "   'Text': 'CEO',\n",
       "   'BeginOffset': 55,\n",
       "   'EndOffset': 58},\n",
       "  {'Score': 0.9934426546096802,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon Worldwide Consumer',\n",
       "   'BeginOffset': 62,\n",
       "   'EndOffset': 87}],\n",
       " [{'Score': 0.9952781200408936,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'Monday',\n",
       "   'BeginOffset': 38,\n",
       "   'EndOffset': 44}],\n",
       " [{'Score': 0.9918432831764221,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': '85%',\n",
       "   'BeginOffset': 97,\n",
       "   'EndOffset': 100}],\n",
       " [{'Score': 0.9667397737503052,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 69,\n",
       "   'EndOffset': 75},\n",
       "  {'Score': 0.6593452095985413,\n",
       "   'Type': 'COMMERCIAL_ITEM',\n",
       "   'Text': 'Prime',\n",
       "   'BeginOffset': 76,\n",
       "   'EndOffset': 81}],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.998184323310852,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': '39 years',\n",
       "   'BeginOffset': 27,\n",
       "   'EndOffset': 35},\n",
       "  {'Score': 0.9692527055740356,\n",
       "   'Type': 'LOCATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 39,\n",
       "   'EndOffset': 57}],\n",
       " [{'Score': 0.9994893670082092,\n",
       "   'Type': 'PERSON',\n",
       "   'Text': 'John Mackey',\n",
       "   'BeginOffset': 5,\n",
       "   'EndOffset': 16},\n",
       "  {'Score': 0.6005990505218506,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 18,\n",
       "   'EndOffset': 36},\n",
       "  {'Score': 0.9980863332748413,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 83,\n",
       "   'EndOffset': 89}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.7808967232704163,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 39,\n",
       "   'EndOffset': 57},\n",
       "  {'Score': 0.9922419786453247,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 62,\n",
       "   'EndOffset': 68}],\n",
       " [{'Score': 0.5150904655456543,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole',\n",
       "   'BeginOffset': 27,\n",
       "   'EndOffset': 32},\n",
       "  {'Score': 0.5104330778121948,\n",
       "   'Type': 'LOCATION',\n",
       "   'Text': 'Foods',\n",
       "   'BeginOffset': 33,\n",
       "   'EndOffset': 38},\n",
       "  {'Score': 0.46311819553375244,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Market',\n",
       "   'BeginOffset': 39,\n",
       "   'EndOffset': 45},\n",
       "  {'Score': 0.9978920817375183,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'Monday',\n",
       "   'BeginOffset': 56,\n",
       "   'EndOffset': 62}],\n",
       " [{'Score': 0.9537372589111328,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': 'two companies',\n",
       "   'BeginOffset': 7,\n",
       "   'EndOffset': 20}],\n",
       " [{'Score': 0.9959214925765991,\n",
       "   'Type': 'DATE',\n",
       "   'Text': 'Monday',\n",
       "   'BeginOffset': 9,\n",
       "   'EndOffset': 15},\n",
       "  {'Score': 0.7406902313232422,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 17,\n",
       "   'EndOffset': 35}],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.9949608445167542,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': '85%',\n",
       "   'BeginOffset': 57,\n",
       "   'EndOffset': 60}],\n",
       " [{'Score': 0.8521405458450317,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': '365',\n",
       "   'BeginOffset': 73,\n",
       "   'EndOffset': 76}],\n",
       " [],\n",
       " [{'Score': 0.9822409749031067,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 69,\n",
       "   'EndOffset': 75},\n",
       "  {'Score': 0.6902766823768616,\n",
       "   'Type': 'COMMERCIAL_ITEM',\n",
       "   'Text': 'Prime',\n",
       "   'BeginOffset': 76,\n",
       "   'EndOffset': 81}],\n",
       " [{'Score': 0.9828807711601257,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Foods Market',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 12},\n",
       "  {'Score': 0.8146139979362488,\n",
       "   'Type': 'COMMERCIAL_ITEM',\n",
       "   'Text': 'Prime',\n",
       "   'BeginOffset': 51,\n",
       "   'EndOffset': 56}],\n",
       " [],\n",
       " [{'Score': 0.8986636400222778,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': '365',\n",
       "   'BeginOffset': 79,\n",
       "   'EndOffset': 82},\n",
       "  {'Score': 0.456102579832077,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': 'Everyday',\n",
       "   'BeginOffset': 83,\n",
       "   'EndOffset': 91}],\n",
       " [{'Score': 0.6238884329795837,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon.com',\n",
       "   'BeginOffset': 73,\n",
       "   'EndOffset': 83}],\n",
       " [{'Score': 0.48343712091445923,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'AmazonFresh',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 11},\n",
       "  {'Score': 0.9897258877754211,\n",
       "   'Type': 'COMMERCIAL_ITEM',\n",
       "   'Text': 'Prime Pantry',\n",
       "   'BeginOffset': 13,\n",
       "   'EndOffset': 25},\n",
       "  {'Score': 0.9780882596969604,\n",
       "   'Type': 'COMMERCIAL_ITEM',\n",
       "   'Text': 'Prime',\n",
       "   'BeginOffset': 30,\n",
       "   'EndOffset': 35}],\n",
       " [{'Score': 0.9963818788528442,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 6},\n",
       "  {'Score': 0.3656037747859955,\n",
       "   'Type': 'COMMERCIAL_ITEM',\n",
       "   'Text': 'Lockers',\n",
       "   'BeginOffset': 7,\n",
       "   'EndOffset': 14}],\n",
       " [{'Score': 0.992739737033844,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon.com',\n",
       "   'BeginOffset': 13,\n",
       "   'EndOffset': 23}],\n",
       " [{'Score': 0.9942862391471863,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 6}],\n",
       " [{'Score': 0.9981287121772766,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Amazon',\n",
       "   'BeginOffset': 29,\n",
       "   'EndOffset': 35},\n",
       "  {'Score': 0.9389330148696899,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 40,\n",
       "   'EndOffset': 58}],\n",
       " [{'Score': 0.9876651167869568,\n",
       "   'Type': 'QUANTITY',\n",
       "   'Text': 'two companies',\n",
       "   'BeginOffset': 38,\n",
       "   'EndOffset': 51}],\n",
       " [],\n",
       " [{'Score': 0.9758713245391846,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 18}],\n",
       " [],\n",
       " [{'Score': 0.773544192314148,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Whole Foods Market',\n",
       "   'BeginOffset': 30,\n",
       "   'EndOffset': 48}],\n",
       " [],\n",
       " [{'Score': 0.9983197450637817,\n",
       "   'Type': 'PERSON',\n",
       "   'Text': 'John Mackey',\n",
       "   'BeginOffset': 18,\n",
       "   'EndOffset': 29},\n",
       "  {'Score': 0.529097318649292,\n",
       "   'Type': 'ORGANIZATION',\n",
       "   'Text': 'Market',\n",
       "   'BeginOffset': 65,\n",
       "   'EndOffset': 71},\n",
       "  {'Score': 0.9928246736526489,\n",
       "   'Type': 'LOCATION',\n",
       "   'Text': 'Austin',\n",
       "   'BeginOffset': 100,\n",
       "   'EndOffset': 106}],\n",
       " [{'Score': 0.9668570160865784,\n",
       "   'Type': 'LOCATION',\n",
       "   'Text': 'Texas',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 5}]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PII Entity Recognition\n",
    "Use Amazon Comprehend to detect PII Entities in the text from the Textract analysis.  \n",
    "What are the types of PII Entities?  \n",
    "* NAME, DATE-TIME, ADDRESS, USERNAME, URL, EMAIL, PHONE, CREDIT-DEBIT-EXPIRY, PASSWORD, AGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_entities = []\n",
    "for line in lines:\n",
    "    response = comp_client.detect_pii_entities(Text=line, LanguageCode='en')\n",
    "    pii_entities.append(response['Entities'])    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Score': 0.9999969601631165,\n",
       "   'Type': 'DATE_TIME',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 15},\n",
       "  {'Score': 0.9999958872795105,\n",
       "   'Type': 'DATE_TIME',\n",
       "   'BeginOffset': 19,\n",
       "   'EndOffset': 26}],\n",
       " [{'Score': 0.9999973773956299,\n",
       "   'Type': 'DATE_TIME',\n",
       "   'BeginOffset': 25,\n",
       "   'EndOffset': 38}],\n",
       " [{'Score': 0.9999973773956299,\n",
       "   'Type': 'DATE_TIME',\n",
       "   'BeginOffset': 85,\n",
       "   'EndOffset': 101}],\n",
       " [{'Score': 0.9923071265220642,\n",
       "   'Type': 'DATE_TIME',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 4}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.9999886751174927,\n",
       "   'Type': 'NAME',\n",
       "   'BeginOffset': 43,\n",
       "   'EndOffset': 53}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.9999813437461853,\n",
       "   'Type': 'NAME',\n",
       "   'BeginOffset': 5,\n",
       "   'EndOffset': 16}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.9999982118606567,\n",
       "   'Type': 'URL',\n",
       "   'BeginOffset': 73,\n",
       "   'EndOffset': 83}],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.999982476234436,\n",
       "   'Type': 'URL',\n",
       "   'BeginOffset': 13,\n",
       "   'EndOffset': 23}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'Score': 0.9997463226318359,\n",
       "   'Type': 'NAME',\n",
       "   'BeginOffset': 18,\n",
       "   'EndOffset': 29},\n",
       "  {'Score': 0.9999929666519165,\n",
       "   'Type': 'ADDRESS',\n",
       "   'BeginOffset': 100,\n",
       "   'EndOffset': 106}],\n",
       " [{'Score': 0.9999842643737793,\n",
       "   'Type': 'ADDRESS',\n",
       "   'BeginOffset': 0,\n",
       "   'EndOffset': 5}]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Topic Modeling\n",
    "Use Amazon Comprehend to extract Topics in the text from the Textract analysis.  \n",
    "\n",
    "In this example, we are running the analysis as an asynchronous job, so the results are stored in a file in the S3 bucket we specify.  \n",
    "This analysis may take up to 10 minutes to run.  \n",
    "\n",
    "The output results are two files:  \n",
    "*topic_terms.csv:*  A list of topics in the collection. For each topic, the list includes the top terms by topic according to their weight.  \n",
    "*doc-topics.csv:*   Lists the documents associated with a topic and the proportion of the document that is concerned with the topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: results/textract-results.txt to s3://am-tmp2/comprehend/textract-results.txt\n"
     ]
    }
   ],
   "source": [
    "# put the file to be analyzed into the s3 bucket\n",
    "# in this example, this file is the results from running textract on a pdf\n",
    "s3dest = f's3://{s3bucket}/{s3prefix}/{textract_results_filename}'\n",
    "!aws s3 cp ./results/$textract_results_filename $s3dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0341c4209663f04171aaa7eb246f6fe8\n"
     ]
    }
   ],
   "source": [
    "# start the Amazon Comprehend Topics Analysis job\n",
    "# create a unique Job Name\n",
    "JobName = 'MyJobName-%d' % (time.time())\n",
    "\n",
    "# Why is this IAM Role needed?\n",
    "comprehend_role = 'arn:aws:iam::662559257807:role/ComprehendDataAccess-SM'\n",
    "\n",
    "request = {\n",
    "   \"ClientRequestToken\": \"string\",\n",
    "   \"DataAccessRoleArn\": comprehend_role,\n",
    "   \"InputDataConfig\": { \n",
    "      \"InputFormat\": \"ONE_DOC_PER_FILE\",\n",
    "      \"S3Uri\": s3dest\n",
    "   },\n",
    "   \"JobName\": JobName,\n",
    "   \"OutputDataConfig\": { \n",
    "      \"S3Uri\": f's3://{s3bucket}/{s3prefix}/'\n",
    "   }\n",
    "}\n",
    "\n",
    "# create the comprehend analysis job\n",
    "response = comp_client.start_topics_detection_job(**request)\n",
    "JobId = response['JobId']\n",
    "print(JobId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "response = comp_client.describe_topics_detection_job(JobId=JobId)\n",
    "status = response['TopicsDetectionJobProperties']['JobStatus']\n",
    "print(status)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobId': '0341c4209663f04171aaa7eb246f6fe8',\n",
       " 'JobName': 'MyJobName-1632756590',\n",
       " 'JobStatus': 'COMPLETED',\n",
       " 'SubmitTime': datetime.datetime(2021, 9, 27, 15, 29, 50, 875000, tzinfo=tzlocal()),\n",
       " 'EndTime': datetime.datetime(2021, 9, 27, 15, 44, 0, 794000, tzinfo=tzlocal()),\n",
       " 'InputDataConfig': {'S3Uri': 's3://am-tmp2/comprehend/textract-results.txt',\n",
       "  'InputFormat': 'ONE_DOC_PER_FILE'},\n",
       " 'OutputDataConfig': {'S3Uri': 's3://am-tmp2/comprehend/662559257807-TOPICS-0341c4209663f04171aaa7eb246f6fe8/output/output.tar.gz'},\n",
       " 'NumberOfTopics': 10,\n",
       " 'DataAccessRoleArn': 'arn:aws:iam::662559257807:role/ComprehendDataAccess-SM'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['TopicsDetectionJobProperties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://am-tmp2/comprehend/662559257807-TOPICS-0341c4209663f04171aaa7eb246f6fe8/output/output.tar.gz to results/output.tar.gz\n",
      "See the following files:\n",
      "-rw-r--r-- 1 root root 2352 Sep 27 15:41 ./results/topic-terms.csv\n",
      "-rw-r--r-- 1 root root 93 Sep 27 15:41 ./results/doc-topics.csv\n"
     ]
    }
   ],
   "source": [
    "# the comprehend analysis results are in the s3 bucket, full path is S3Uri\n",
    "s3uri = response['TopicsDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
    "basename = os.path.basename(s3uri)\n",
    "\n",
    "# copy the 'output.tar.gz' file from the s3 bucket to the results folder\n",
    "!aws s3 cp $s3uri $results_dir\n",
    "\n",
    "# extract the contents of this tarball, which are two files: topic-terms.csv, doc-topics.csv\n",
    "!(cd $results_dir; tar xzf $basename)\n",
    "!(cd $results_dir; rm -f $basename)\n",
    "\n",
    "print('See the following files:')\n",
    "!ls -l $results_dir/topic-terms.csv\n",
    "!ls -l $results_dir/doc-topics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TopicsDetectionJobProperties': {'JobId': '27d8c680451146edb26a006424c7f9fb',\n",
       "  'JobName': 'MyJobName-1632753183',\n",
       "  'JobStatus': 'COMPLETED',\n",
       "  'SubmitTime': datetime.datetime(2021, 9, 27, 14, 33, 3, 487000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2021, 9, 27, 15, 3, 19, 262000, tzinfo=tzlocal()),\n",
       "  'InputDataConfig': {'S3Uri': 's3://am-tmp2/comprehend/textract-results.txt',\n",
       "   'InputFormat': 'ONE_DOC_PER_LINE'},\n",
       "  'OutputDataConfig': {'S3Uri': 's3://am-tmp2/comprehend/662559257807-TOPICS-27d8c680451146edb26a006424c7f9fb/output/output.tar.gz'},\n",
       "  'NumberOfTopics': 10,\n",
       "  'DataAccessRoleArn': 'arn:aws:iam::662559257807:role/ComprehendDataAccess-SM'},\n",
       " 'ResponseMetadata': {'RequestId': '490a64a7-b1bb-4278-a27c-2a9ceb6963d5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '490a64a7-b1bb-4278-a27c-2a9ceb6963d5',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '632',\n",
       "   'date': 'Mon, 27 Sep 2021 15:21:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
